{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model-training.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "PyTorch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sOBf9FoVO5gY"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ypbH-_VO5gZ"
      },
      "source": [
        "## Create Filesystem\n",
        "This notebook is primarily meant to be executed in Colab as a computational backend. If you want to run on your own hardware with data, you need to set `data_dir` and `ALLOW_IO`\n",
        "\n",
        "This notebook viewable directly on Colab from [https://colab.research.google.com/github/rcharan/phutball/blob/master/pytorch-implementation/model-training.ipynb](https://colab.research.google.com/github/rcharan/phutball/blob/master/pytorch-implementation/model-training.ipynb) (it is a mirror of github). But if it has moved branches or you are looking at a past commit, look at the [Google instructions](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb) on where to find this file.\n",
        "\n",
        "The workflow is:\n",
        " - Data stored in (my personal/private) Google Drive\n",
        " - Utilities/library files (for importing) on github, edited on local hardware and pushed to github.\n",
        " - Notebook hosted on github, edited both in Colab or locally (depending on the relative value of having a GPU attached versus being able to use regular Jupyter keyboard shortcuts/a superior interface)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RY-nqnzUzB5k",
        "outputId": "2f5df152-a0b3-469c-802a-314dcbed0083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Attempt Colab setup if on Colab\n",
        "try:\n",
        "  import google.colab\n",
        "except:\n",
        "  ALLOW_IO = False\n",
        "else:\n",
        "  # Mount Google Drive at data_dir\n",
        "  #  (for data)\n",
        "  from google.colab import drive\n",
        "  from os.path import join\n",
        "  ROOT = '/content/drive'\n",
        "  DATA = 'My Drive/phutball'\n",
        "  drive.mount(ROOT)\n",
        "  ALLOW_IO = True\n",
        "  data_dir = join(ROOT, DATA)\n",
        "  !mkdir \"{data_dir}\"     # in case we haven't created it already   \n",
        "\n",
        "  # Pull in code from github\n",
        "  %cd /content\n",
        "  github_repo = 'https://github.com/rcharan/phutball'\n",
        "  !git clone -b master {github_repo}\n",
        "  %cd /content/phutball\n",
        "  \n",
        "  # Point python to code base\n",
        "  import sys\n",
        "  sys.path.append('/content/phutball/pytorch-implementation')\n",
        "\n",
        "  # Updater for library functions changed on local hardware and pushed to github\n",
        "  #  (circuitous, I know)\n",
        "  def update_repo():\n",
        "    !git pull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n",
            "mkdir: cannot create directory â€˜/content/drive/My Drive/phutballâ€™: File exists\n",
            "/content\n",
            "Cloning into 'phutball'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 2037 (delta 27), reused 22 (delta 10), pack-reused 1984\u001b[K\n",
            "Receiving objects: 100% (2037/2037), 38.53 MiB | 10.70 MiB/s, done.\n",
            "Resolving deltas: 100% (1278/1278), done.\n",
            "/content/phutball\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF1C55w-O5gg"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jbaorYhzwUze",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "\n",
        "# Codebase\n",
        "from lib.model_v3          import TDConway\n",
        "from lib.off_policy        import EpsilonGreedy\n",
        "from lib.optim             import AlternatingTDLambda\n",
        "\n",
        "from lib.training          import training_loop\n",
        "\n",
        "from lib.utilities         import config, lfilter\n",
        "from lib.testing_utilities import create_state, visualize_state, boards\n",
        "from lib.timer             import Timer\n",
        "\n",
        "from lib.move_selection    import get_next_move_training\n",
        "\n",
        "\n",
        "# Graphics for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "plt.ioff()\n",
        "\n",
        "# PyTorch\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GOk4kKeOO5gm"
      },
      "source": [
        "## Device Management Utilities\n",
        "Setup for GPU, CPU, or (not working well/fully implemented) TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A7ETHYgbO5gm",
        "outputId": "0e0dce96-224b-4f59-af11-b5296a55bc33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "use_tpu = False\n",
        "\n",
        "if use_tpu:\n",
        "  # This section doesn't run\n",
        "  # Install PyTorch/XLA\n",
        "  VERSION = \"nightly\" #[\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
        "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "  !python pytorch-xla-env-setup.py --version $VERSION\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "  \n",
        "  # Set the device\n",
        "  device = xm.xla_device()\n",
        "  \n",
        "  # Memory inspection\n",
        "  def print_memory_usage():\n",
        "    print('TPU memory inspection not implemented')\n",
        "  def print_max_memory_usage():\n",
        "    print('TPU memory inspection not implemented')\n",
        "  def garbage_collect():\n",
        "    gc.collect() # No TPU specific implementation yet\n",
        "    \n",
        "elif torch.cuda.is_available():\n",
        "  # Set the device\n",
        "  device = torch.device('cuda')\n",
        "  \n",
        "  # Echo GPU info\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  print(gpu_info)\n",
        "  \n",
        "  # Memory inspection and management\n",
        "  from lib.memory import (\n",
        "    print_memory_usage_cuda     as print_memory_usage,\n",
        "    print_max_memory_usage_cuda as print_max_memory_usage,\n",
        "    garbage_collect_cuda        as garbage_collect\n",
        "  )\n",
        "\n",
        "else:\n",
        "  # Set the device to CPU\n",
        "  device = torch.device('cpu')\n",
        "  \n",
        "  # Echo RAM info\n",
        "  from psutil import virtual_memory\n",
        "  from lib.memory import format_bytes\n",
        "  ram = virtual_memory().total\n",
        "  print(format_bytes(ram), 'available memory on CPU-based runtime')\n",
        "  \n",
        "  # Memory inspection and management\n",
        "  from lib.memory import (\n",
        "    print_memory_usage, \n",
        "    print_max_memory_usage,\n",
        "    garbage_collect\n",
        "  )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun  7 17:03:11 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    26W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KxB31wNMO5hG"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tHORM9o9TCgY",
        "colab": {}
      },
      "source": [
        "def save(fname, model):\n",
        "  state_dict = {\n",
        "      'model' : model.state_dict(),\n",
        "  }\n",
        "  torch.save(state_dict, f'{data_dir}/{fname}.pt')\n",
        "\n",
        "def fname(version, game_num):\n",
        "  return f'v{version}-{game_num}'\n",
        "  \n",
        "def load(version, game_num, model):\n",
        "  sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt')\n",
        "  model.load_state_dict(sd['model'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0cd-9BUVBJOM"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZgnPBVNB4XTo"
      },
      "source": [
        "## Fit one cycle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MTstggDJiTjM",
        "colab": {}
      },
      "source": [
        "from lib.pretraining.fit_one_cycle import fit_one_cycle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y943nd1nxNnL",
        "outputId": "8a9bb864-10d5-4e45-c12b-79b8217e7b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = TDConway(config).to(device)\n",
        "data = fit_one_cycle(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6942/6942 [==============================] - 73s 10ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xgvyC2ptxvsY",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0a-xUM-4x8eM",
        "outputId": "2a8a4b26-970f-409c-e2e2-91a31bc046ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "df = pd.DataFrame(data, columns = ['lr', 'loss'])\n",
        "df['loss'] = df.loss.apply(lambda l : l.item())\n",
        "df = df.groupby('lr').mean().reset_index()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "sns.lineplot(x = 'lr', y='loss', data = df, ax = ax)\n",
        "ax.set_xscale('log', basex = 10)\n",
        "ax.set_yscale('log', basey = 10)\n",
        "fig"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lrt0AqtH4iYO"
      },
      "source": [
        "## Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d_TWjyDcidf_",
        "colab": {}
      },
      "source": [
        "from lib.pretraining.pre_training import pre_train\n",
        "from torch.optim import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BfsZxT94iaIx",
        "outputId": "e07266f5-9cbe-43c8-b33c-acbce455c6a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = TDConway(config).to(device)\n",
        "optimizer = SGD(model.parameters(), lr = 0.05)\n",
        "\n",
        "pre_train(model, optimizer, loops = 35000, batch_size = 300)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35000/35000 [==============================] - 464s 13ms/step - loss: 0.0012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urTf19bSqUNb",
        "colab": {}
      },
      "source": [
        "version = '0.3.2'\n",
        "game_num = 'pre35000x300'\n",
        "\n",
        "save(fname(version, game_num), model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mlOE_I84O5hD"
      },
      "source": [
        "## Profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWmJPdMtDgHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lib.utilities import product"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqA5FtRSCn5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_state = create_state('H10').to(device)\n",
        "epsilon_greedy = EpsilonGreedy(0.01)\n",
        "\n",
        "def num_params(model):\n",
        "  return sum(\n",
        "      product(t.shape) for t in model.parameters()\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Etz9nnawU0i",
        "outputId": "6df2d484-ef50-4f0d-e53d-70d70e43089b",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from torch.optim import SGD\n",
        "# version = '0.3.1'\n",
        "# game_num = '70000'\n",
        "model     = TDConway(config).to(device)\n",
        "model     = load(version, game_num, model)\n",
        "\n",
        "optimizer = AlternatingTDLambda(model.parameters(), alpha = 0.05, lamda = 0.9)\n",
        "\n",
        "print(f'{num_params(model):,d} parameters')\n",
        "%timeit get_next_move_training(initial_state, model, device)\n",
        "%timeit training_loop(model, optimizer, 1, device, off_policy = epsilon_greedy)\n",
        "# %prun training_loop(model, optimizer, 1, device, off_policy = epsilon_greedy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,935,105 parameters\n",
            "100 loops, best of 3: 3.28 ms per loop\n",
            "1/1 [==============================] - 0s 622us/step\n",
            "1/1 [==============================] - 0s 188us/step\n",
            "1/1 [==============================] - 0s 192us/step\n",
            "1/1 [==============================] - 0s 172us/step\n",
            "1 loop, best of 3: 473 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eqLsixqoP3kV"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PB5nj1edBoaH",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "eastern = timezone('US/Eastern')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OsYoeCm2q-Wh",
        "colab": {}
      },
      "source": [
        "epsilon_greedy = EpsilonGreedy(0.05)\n",
        "model = TDConway(config).to(device)\n",
        "optimizer = AlternatingTDLambda(model.parameters(), 0.05, 0.9)\n",
        "\n",
        "version  = '0.3.2'\n",
        "game_num = 'pre35000x300'\n",
        "\n",
        "load(version, game_num, model);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92NgliNkT7vm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a20bef84-d1e5-41eb-cb7d-eaea74ce137a"
      },
      "source": [
        "version = '0.3.2'\n",
        "game_num = 0\n",
        "\n",
        "batch_size = 2000\n",
        "\n",
        "while True: # Until Colab or User disconnects out of boredom\n",
        "  try:\n",
        "    training_loop(model, optimizer, batch_size, device, off_policy = epsilon_greedy, verbose = 1)\n",
        "    game_num += batch_size\n",
        "\n",
        "    save(fname(version, game_num), model)\n",
        "\n",
        "    print(f'Finished {game_num} games at', datetime.now(eastern).strftime('%I:%M%p %Z'))\n",
        "  except KeyboardInterrupt:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 1861s 931ms/step\n",
            "Finished 2000 games at 01:42PM EDT\n",
            " 840/2000 [===========>..................] - ETA: 19:08"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hywC_0PRNKdc",
        "colab": {}
      },
      "source": [
        "# Versioning:\n",
        "#  Major versions - major change in approach\n",
        "#  Minor versions - incompatible architecture tweaks\n",
        "#  Build          - retraining or changes in training parameters\n",
        "#  Game number    - number of games trained or pre{E}x{B} where E is the the\n",
        "#                   number of batches and B is the batch size for pre-training\n",
        "# Example: v0.1.2 @400 is the second attempt at training the v0.1 architecture\n",
        "#  and was trained for 400 games\n",
        "\n",
        "# Performance benchmarks.\n",
        "#  GPU benchmarks are on a P100 unless otherwise stated\n",
        "#    per move    : training-relevant\n",
        "#    forward pass: evaluation (arena mode) relevant\n",
        "#  CPU benchmarks are for inference on a fixed set of 300 randomly\n",
        "#    generated boards on an Intel i5 chipset. (deployment-relevant)\n",
        "#  Memory consumption has not been an issue\n",
        "\n",
        "# v0.1: architecture from model_v1. Training: Alternating TD(Î»)\n",
        "#  ~60M params (59,943,809)\n",
        "#  GPU: 100â€“110ms/move with 50-60ms for forward pass\n",
        "#  CPU: 8.1s Â± 0.5s \n",
        "#  alpha = 0.01, lambda = 0.9, epsilon = 0.1\n",
        "#\n",
        "#  - v0.1.1 - don't use, bug in training\n",
        "#  - v0.1.2 - Use. available @400. Win rate v RandoTron 51% (ðŸ˜¢)\n",
        "\n",
        "# v0.2: architecture from model_v2. Smaller Residual ConvNet (17 layers)\n",
        "#  Training: Alternating TD(Î») WITH pretraining to prefer the ball to the\n",
        "#   right on randomly generated boards\n",
        "#  ~4.4M params (4,381,505)\n",
        "#  GPU: 30-35ms/move with ~12ms for forward pass\n",
        "#  CPU: 1.1s Â± 0.02s\n",
        "#\n",
        "# - v0.2.1 - Available @pre10000x300, @400, @1500, @3500\n",
        "#          - Hyperparameters same as v0.1\n",
        "#            Win rate v RandoTron \n",
        "#            - @pre-trained: 75.4% Â±1.4% (!?)\n",
        "#            - @400: 49%\n",
        "#            - @1500: 56.9% Â±1.8%\n",
        "#            - @3500: 54.8% Â±1.7%\n",
        "#            - In further increments of 500 as [4000, 4500, ..., 20500]\n",
        "#            - @10500: 60.3% Â±1.6%\n",
        "#            - @17500: 59.5% Â±1.2%\n",
        "# - v0.2.2 - Increased pretraining, epsilon = 0.01\n",
        "#          - Available @pre30000x300 (71.2% Â± 2.3%)\n",
        "#          - And in increments of 500 [500, 1000, ..., 82000]\n",
        "#          - @17500: 71.5% Â±1.1%\n",
        "#          - @82000: 99.8% Â±0.1%\n",
        "\n",
        "# v0.3: architecture from model_v3. Much smaller (7 layers), no residuals\n",
        "# ~1.9M params (1,935,105)\n",
        "# alpha = 0.05, epsilon = 0.1, lambda = 0.9\n",
        "#\n",
        "# -v0.3.1 - Available at @pre40000x300, increments of 1000\n",
        "#         - @27000: 71.3% Â±1.1%\n",
        "#         - @73000: 58.8% \n",
        "# -v0.3.2 - With Îµ = 0.05"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hB7XLdBFAI1i"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eYsHmg68JIkN",
        "colab": {}
      },
      "source": [
        "from lib.arena import Player, Battle, RandoTron"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oNbNXAIuJLS7",
        "colab": {}
      },
      "source": [
        "# Player 1\n",
        "model = TDConway(config).to(device)\n",
        "version  = '0.3.1'\n",
        "game_num = 73000\n",
        "sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt', map_location = device)\n",
        "model.load_state_dict(sd['model'])\n",
        "\n",
        "td_conway = Player(model, name = f'TD Conway v{version} @{game_num}')\n",
        "td_conway.eval()\n",
        "randotron = RandoTron()\n",
        "battle    = Battle(td_conway, randotron, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ALkfa_V9cjH-",
        "outputId": "ca78badf-cfb3-498e-ef08-37ac3f0ab518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "battle.play_match(1600, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1600/1600 [==============================] - 361s 226ms/step\n",
            "1600 games were played between TD Conway v0.3.1 @73000 and RandoTron with 0 draws.\n",
            "The winner was TD Conway v0.3.1 @73000 with a 58.8% win rate!\n",
            "TD Conway v0.3.1 @73000 on average won in a game of length 81.1.\n",
            "RandoTron on average won in a game of length 75.7\n",
            "Overall average length of game was 78.865\n",
            "Total time taken: 6:00 at\n",
            " - 226ms per finished game.\n",
            " - 3ms per move in a finished game\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4O0diFCd6M4T",
        "colab": {}
      },
      "source": [
        "# Player 1 @3500\n",
        "model = TDConway(config).to(device)\n",
        "version  = '0.2.1'\n",
        "game_num = 3500\n",
        "sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt', map_location = device)\n",
        "model.load_state_dict(sd['model'])\n",
        "td_conway_1 = Player(model, name = f'TD Conway v{version} @{game_num}')\n",
        "td_conway_1.eval()\n",
        "\n",
        "# Player 2 @ 10500\n",
        "model = TDConway(config).to(device)\n",
        "version  = '0.2.1'\n",
        "game_num = 10500\n",
        "sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt', map_location = device)\n",
        "model.load_state_dict(sd['model'])\n",
        "td_conway_2 = Player(model, name = f'TD Conway v{version} @{game_num}')\n",
        "td_conway_2.eval()\n",
        "\n",
        "battle    = Battle(td_conway_1, td_conway_2, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XNwLyUBQ-LU3",
        "colab": {}
      },
      "source": [
        "battle.play_match(900, device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}