{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOBf9FoVO5gY"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ypbH-_VO5gZ"
   },
   "source": [
    "## Create Filesystem\n",
    "This notebook is primarily meant to be executed in Colab as a computational backend. If you want to run on your own hardware with data, you need to set `data_dir` and `ALLOW_IO`\n",
    "\n",
    "This notebook viewable directly on Colab from [https://colab.research.google.com/github/rcharan/phutball/blob/master/pytorch-implementation/model-training.ipynb](https://colab.research.google.com/github/rcharan/phutball/blob/master/pytorch-implementation/model-training.ipynb) (it is a mirror of github). But if it has moved branches or you are looking at a past commit, look at the [Google instructions](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb) on where to find this file.\n",
    "\n",
    "The workflow is:\n",
    " - Data stored in (my personal/private) Google Drive\n",
    " - Utilities/library files (for importing) on github, edited on local hardware and pushed to github.\n",
    " - Notebook hosted on github, edited both in Colab or locally (depending on the relative value of having a GPU attached versus being able to use regular Jupyter keyboard shortcuts/a superior interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "RY-nqnzUzB5k",
    "outputId": "93305712-8433-4329-d16d-d1dc9f0f6198"
   },
   "outputs": [],
   "source": [
    "# Attempt Colab setup if on Colab\n",
    "try:\n",
    "  import google.colab\n",
    "except:\n",
    "  ALLOW_IO = False\n",
    "else:\n",
    "  # Mount Google Drive at data_dir\n",
    "  #  (for data)\n",
    "  from google.colab import drive\n",
    "  from os.path import join\n",
    "  ROOT = '/content/drive'\n",
    "  DATA = 'My Drive/phutball'\n",
    "  drive.mount(ROOT)\n",
    "  ALLOW_IO = True\n",
    "  data_dir = join(ROOT, DATA)\n",
    "  !mkdir \"{data_dir}\"     # in case we haven't created it already   \n",
    "\n",
    "  # Pull in code from github\n",
    "  %cd /content\n",
    "  github_repo = 'https://github.com/rcharan/phutball'\n",
    "  !git clone -b master {github_repo}\n",
    "  %cd /content/phutball\n",
    "  \n",
    "  # Point python to code base\n",
    "  import sys\n",
    "  sys.path.append('/content/phutball/pytorch-implementation')\n",
    "\n",
    "  # Updater for library functions changed on local hardware and pushed to github\n",
    "  #  (circuitous, I know)\n",
    "  def update_repo():\n",
    "    !git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zF1C55w-O5gg"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbaorYhzwUze"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "# Codebase\n",
    "from lib.model_v3          import TDConway\n",
    "from lib.off_policy        import EpsilonGreedy\n",
    "from lib.optim             import AlternatingTDLambda\n",
    "\n",
    "from lib.training          import training_loop\n",
    "\n",
    "from lib.utilities         import config, lfilter\n",
    "from lib.testing_utilities import create_state, visualize_state, boards\n",
    "from lib.timer             import Timer\n",
    "\n",
    "from lib.move_selection    import get_next_move_training\n",
    "\n",
    "\n",
    "# Graphics for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "plt.ioff()\n",
    "\n",
    "# PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOk4kKeOO5gm"
   },
   "source": [
    "## Device Management Utilities\n",
    "Setup for GPU, CPU, or (not working well/fully implemented) TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "A7ETHYgbO5gm",
    "outputId": "e9750bbf-4631-40fd-c963-837719a78bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.00GiB available memory on CPU-based runtime\n"
     ]
    }
   ],
   "source": [
    "use_tpu = False\n",
    "\n",
    "if use_tpu:\n",
    "  # This section doesn't run\n",
    "  # Install PyTorch/XLA\n",
    "  VERSION = \"nightly\" #[\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
    "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "  !python pytorch-xla-env-setup.py --version $VERSION\n",
    "  import torch_xla\n",
    "  import torch_xla.core.xla_model as xm\n",
    "  \n",
    "  # Set the device\n",
    "  device = xm.xla_device()\n",
    "  \n",
    "  # Memory inspection\n",
    "  def print_memory_usage():\n",
    "    print('TPU memory inspection not implemented')\n",
    "  def print_max_memory_usage():\n",
    "    print('TPU memory inspection not implemented')\n",
    "  def garbage_collect():\n",
    "    gc.collect() # No TPU specific implementation yet\n",
    "    \n",
    "elif torch.cuda.is_available():\n",
    "  # Set the device\n",
    "  device = torch.device('cuda')\n",
    "  \n",
    "  # Echo GPU info\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  print(gpu_info)\n",
    "  \n",
    "  # Memory inspection and management\n",
    "  from lib.memory import (\n",
    "    print_memory_usage_cuda     as print_memory_usage,\n",
    "    print_max_memory_usage_cuda as print_max_memory_usage,\n",
    "    garbage_collect_cuda        as garbage_collect\n",
    "  )\n",
    "\n",
    "else:\n",
    "  # Set the device to CPU\n",
    "  device = torch.device('cpu')\n",
    "  \n",
    "  # Echo RAM info\n",
    "  from psutil import virtual_memory\n",
    "  from lib.memory import format_bytes\n",
    "  ram = virtual_memory().total\n",
    "  print(format_bytes(ram), 'available memory on CPU-based runtime')\n",
    "  \n",
    "  # Memory inspection and management\n",
    "  from lib.memory import (\n",
    "    print_memory_usage, \n",
    "    print_max_memory_usage,\n",
    "    garbage_collect\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KxB31wNMO5hG"
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHORM9o9TCgY"
   },
   "outputs": [],
   "source": [
    "def save(fname, model):\n",
    "  state_dict = {\n",
    "      'model' : model.state_dict(),\n",
    "  }\n",
    "  torch.save(state_dict, f'{data_dir}/{fname}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WXYUZNU6qQWh"
   },
   "outputs": [],
   "source": [
    "def fname(version, game_num):\n",
    "  return f'v{version}-{game_num}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wl2pMjzH4Iex"
   },
   "outputs": [],
   "source": [
    "def load(version, game_num, model):\n",
    "  sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt')\n",
    "  model.load_state_dict(sd['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cd-9BUVBJOM"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgnPBVNB4XTo"
   },
   "source": [
    "## Fit one cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTstggDJiTjM"
   },
   "outputs": [],
   "source": [
    "from lib.pretraining.fit_one_cycle import fit_one_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y943nd1nxNnL",
    "outputId": "dd2f882a-d3c4-4c62-fddb-34a187aca70e"
   },
   "outputs": [],
   "source": [
    "model = TDConway(config).to(device)\n",
    "data = fit_one_cycle(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in model.named_parameters():\n",
    "  print(p.shape, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xgvyC2ptxvsY"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "colab_type": "code",
    "id": "0a-xUM-4x8eM",
    "outputId": "a4dedb3a-9d20-432b-fea2-c566f199e965"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns = ['lr', 'loss'])\n",
    "df['loss'] = df.loss.apply(lambda l : l.item())\n",
    "df = df.groupby('lr').mean().reset_index()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(x = 'lr', y='loss', data = df, ax = ax)\n",
    "ax.set_xscale('log', basex = 10)\n",
    "ax.set_yscale('log', basey = 10)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lrt0AqtH4iYO"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_TWjyDcidf_"
   },
   "outputs": [],
   "source": [
    "from lib.pretraining.pre_training import pre_train\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BfsZxT94iaIx",
    "outputId": "592d0717-0be1-44f2-f696-31df8ab3ab32"
   },
   "outputs": [],
   "source": [
    "model = TDConway(config).to(device)\n",
    "optimizer = SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "pre_train(model, optimizer, loops = 10000, batch_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "weZKL4738w78",
    "outputId": "f0cf207b-3b29-4e97-c3b8-9582fc9cbff9"
   },
   "outputs": [],
   "source": [
    "pre_train(model, optimizer, loops = 10000, batch_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "veSorb7Z_PLG",
    "outputId": "b090588f-2a20-44d8-b550-11261fbd725d"
   },
   "outputs": [],
   "source": [
    "pre_train(model, optimizer, loops = 10000, batch_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urTf19bSqUNb"
   },
   "outputs": [],
   "source": [
    "version = '0.2.2'\n",
    "game_num = 'pre30000x300'\n",
    "\n",
    "save(fname(version, game_num), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mlOE_I84O5hD"
   },
   "source": [
    "## Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "id": "-Etz9nnawU0i",
    "outputId": "5af83d07-ff64-43fc-fc96-e1bd01df5bbf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from torch.optim import SGD\n",
    "# version = '0.2.2'\n",
    "# game_num = '70000'\n",
    "# model = TDConway(config).to(device)\n",
    "# optimizer = SGD(model.parameters(), lr = 0.01)\n",
    "# model = load(version, game_num, model)\n",
    "\n",
    "# # %timeit get_next_move_training(initial_state, model, device)\n",
    "# %timeit training_loop(model, optimizer, 1, device, off_policy = epsilon_greedy)\n",
    "# %prun training_loop(model, optimizer, 1, device, off_policy = epsilon_greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqLsixqoP3kV"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PB5nj1edBoaH"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "eastern = timezone('US/Eastern')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsYoeCm2q-Wh"
   },
   "outputs": [],
   "source": [
    "epsilon_greedy = EpsilonGreedy(0.01)\n",
    "model = TDConway(config).to(device)\n",
    "optimizer = AlternatingTDLambda(model.parameters(), 0.01, 0.9)\n",
    "\n",
    "version  = '0.2.2'\n",
    "game_num = 82000\n",
    "\n",
    "load(version, game_num, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "92NgliNkT7vm",
    "outputId": "160c5d5c-530b-47d2-c00d-bcb55647ea2d"
   },
   "outputs": [],
   "source": [
    "version = '0.2.2'\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "while True: # Until Colab or User disconnects out of boredom\n",
    "  try:\n",
    "    training_loop(model, optimizer, batch_size, device, off_policy = epsilon_greedy, verbose = 1)\n",
    "    game_num += batch_size\n",
    "\n",
    "    save(fname(version, game_num), model)\n",
    "\n",
    "    print(f'Finished {game_num} games at', datetime.now(eastern).strftime('%I:%M%p %Z'))\n",
    "  except KeyboardInterrupt:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BSf5Sb434Rq"
   },
   "source": [
    "nope now it's slow :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hywC_0PRNKdc"
   },
   "outputs": [],
   "source": [
    "# Versioning:\n",
    "#  Major versions - major change in approach\n",
    "#  Minor versions - incompatible architecture tweaks\n",
    "#  Build          - retraining or changes in training parameters\n",
    "#  Game number    - number of games trained or pre{E}x{B} where E is the the\n",
    "#                   number of batches and B is the batch size for pre-training\n",
    "# Example: v0.1.2 @400 is the second attempt at training the v0.1 architecture\n",
    "#  and was trained for 400 games\n",
    "\n",
    "# Performance benchmarks.\n",
    "#  GPU benchmarks are on a P100 unless otherwise stated\n",
    "#    per move    : training-relevant\n",
    "#    forward pass: evaluation (arena mode) relevant\n",
    "#  CPU benchmarks are for inference on a fixed set of 300 randomly\n",
    "#    generated boards on an Intel i5 chipset. (deployment-relevant)\n",
    "#  Memory consumption has not been an issue\n",
    "\n",
    "# v0.1: architecture from model_v1. Training: Alternating TD(Î»)\n",
    "#  ~60M params (59,943,809)\n",
    "#  GPU: 100â€“110ms/move with 50-60ms for forward pass\n",
    "#  CPU: 8.1s Â± 0.5s \n",
    "#  alpha = 0.01, lambda = 0.9, epsilon = 0.1\n",
    "#\n",
    "#  - v0.1.1 - don't use, bug in training\n",
    "#  - v0.1.2 - Use. available @400. Win rate v RandoTron 51% (ðŸ˜¢)\n",
    "\n",
    "# v0.2: architecture from model_v2.\n",
    "#  Training: Alternating TD(Î») WITH pretraining to prefer the ball to the\n",
    "#   right on randomly generated boards\n",
    "#  ~4.4M params (4,381,505)\n",
    "#  GPU: 30-35ms/move with ~12ms for forward pass\n",
    "#  CPU: 1.1s Â± 0.02s\n",
    "#\n",
    "# - v0.2.1 - Available @pre10000x300, @400, @1500, @3500\n",
    "#          - Hyperparameters same as v0.1\n",
    "#            Win rate v RandoTron \n",
    "#            - @pre-trained: 75.4% Â±1.4% (!?)\n",
    "#            - @400: 49%\n",
    "#            - @1500: 56.9% Â±1.8%\n",
    "#            - @3500: 54.8% Â±1.7%\n",
    "#            - In further increments of 500 as [4000, 4500, ..., 20500]\n",
    "#            - @10500: 60.3% Â±1.6%\n",
    "#            - @17500: 59.5% Â±1.2%\n",
    "# - v0.2.2 - Increased pretraining, epsilon = 0.01\n",
    "#          - Available @pre30000x300 (71.2% Â± 2.3%)\n",
    "#          - And in increments of 500 [500, 1000, ..., 82000]\n",
    "#          - @17500: 71.5% Â±1.1%\n",
    "#          - @82000: 99.8% Â±0.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hB7XLdBFAI1i"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYsHmg68JIkN"
   },
   "outputs": [],
   "source": [
    "from lib.arena import Player, Battle, RandoTron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNbNXAIuJLS7"
   },
   "outputs": [],
   "source": [
    "# Player 1\n",
    "model = TDConway(config).to(device)\n",
    "version  = '0.2.2'\n",
    "game_num = 82000\n",
    "sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt', map_location = device)\n",
    "model.load_state_dict(sd['model'])\n",
    "# optimizer.load_state_dict(sd['optim'])\n",
    "\n",
    "td_conway = Player(model, name = f'TD Conway v{version} @{game_num}')\n",
    "td_conway.eval()\n",
    "randotron = RandoTron()\n",
    "battle    = Battle(td_conway, randotron, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "ALkfa_V9cjH-",
    "outputId": "c07adc0d-b9d7-4fd0-d105-f271296aec2e"
   },
   "outputs": [],
   "source": [
    "battle.play_match(1600, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4O0diFCd6M4T"
   },
   "outputs": [],
   "source": [
    "# Player 1 @3500\n",
    "model = TDConway(config).to(device)\n",
    "version  = '0.2.1'\n",
    "game_num = 3500\n",
    "sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt', map_location = device)\n",
    "model.load_state_dict(sd['model'])\n",
    "td_conway_1 = Player(model, name = f'TD Conway v{version} @{game_num}')\n",
    "td_conway_1.eval()\n",
    "\n",
    "# Player 2 @ 10500\n",
    "model = TDConway(config).to(device)\n",
    "version  = '0.2.1'\n",
    "game_num = 10500\n",
    "sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt', map_location = device)\n",
    "model.load_state_dict(sd['model'])\n",
    "td_conway_2 = Player(model, name = f'TD Conway v{version} @{game_num}')\n",
    "td_conway_2.eval()\n",
    "\n",
    "battle    = Battle(td_conway_1, td_conway_2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNwLyUBQ-LU3"
   },
   "outputs": [],
   "source": [
    "battle.play_match(900, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "model-training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
